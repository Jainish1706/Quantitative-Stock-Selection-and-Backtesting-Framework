# -*- coding: utf-8 -*-
"""Project_2_Real.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DtJqOri2fs9gkM2bthG3waXr0BkY2Vk9

**Import Libraries**
"""

!pip install pandas_ta

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import os
import yfinance as yf
import numpy as np
import time
from datetime import timedelta
import pandas_ta as ta
import matplotlib.pyplot as plt

"""**Mounting Google drive**"""

from google.colab import drive
drive.mount('/content/drive')

"""**Code for selecting stocks using fundamental analysis**

"""

def stock_selection(folder_path):
  parent_folder_path = folder_path

  # Initialize a dictionary to hold results for each sector
  sector_dataframes = {}

  # List to store common stocks across all sectors
  all_common_stocks = []

  # Walk through subfolders
  for root, dirs, files in os.walk(parent_folder_path):
      if root == parent_folder_path:
          continue  # Skip the parent folder itself

      sector = os.path.basename(root)  # Extract sector name from folder name
      sector_means = []  # List to store mean results for the sector

      for file_name in files:
          if file_name.endswith('.xlsx'):  # Only process Excel files
              file_path = os.path.join(root, file_name)
              # print(f"Processing file: {file_path}")

              # Read and clean the Excel file
              data = pd.read_excel(file_path, sheet_name='Ratio_Analysis', skiprows=3)
              data = data.dropna(axis=1, how='all')  # Drop columns with all NaN values
              data.rename(
                  columns=lambda x: pd.to_datetime(x, errors='coerce').strftime('%Y-%m-%d')
                  if pd.to_datetime(x, errors='coerce') is not pd.NaT else x, inplace=True
              )

              # Transpose and clean data
              data_transposed = data.T
              data_transposed = data_transposed.fillna(0)
              data_transposed.columns = data_transposed.iloc[0]
              data_transposed = data_transposed[1:]
              data_transposed = data_transposed.drop(columns='Price', errors='ignore')

              # Split data into high and low indicators
              data_transposed_high = data_transposed[['EBITDA Margin', 'PAT Margin', 'ROE', 'ROCE']]
              data_transposed_low = data_transposed[['PE', 'PEG', 'D/E', 'P/B']]

              # Normalize and apply PCA
              scaler = StandardScaler()
              data_normalized_high = scaler.fit_transform(data_transposed_high)
              data_normalized_low = scaler.fit_transform(data_transposed_low)

              pca = PCA(n_components=1)
              pca_result_high = pca.fit_transform(data_normalized_high)
              pca_result_low = pca.fit_transform(data_normalized_low)

              # Calculate mean
              mean_high = pca_result_high.mean()
              mean_low = pca_result_low.mean()

              # Append to sector_means
              sector_means.append({
                  "Stock": os.path.splitext(file_name)[0],  # Stock name from file name
                  "Mean_High": mean_high,
                  "Mean_Low": mean_low
              })

      # Convert sector_means to DataFrame
      sector_df = pd.DataFrame(sector_means)
      sector_dataframes[sector] = sector_df  # Store in dictionary

      if not sector_df.empty:
          # Get sorted DataFrames
          sector_df1 = sector_df[['Stock', 'Mean_High']].sort_values(by='Mean_High', ascending=False)
          sector_df2 = sector_df[['Stock', 'Mean_Low']].sort_values(by='Mean_Low')

          n = len(sector_df1)
          m = len(sector_df2)
          reqd = n//2 if n % 2 == 0 else (n+1)//2

          # Get the first 50 percent rows of each DataFrame
          top_n_high = set(sector_df1.head(reqd)['Stock'])
          top_n_low = set(sector_df2.head(reqd)['Stock'])

          # Find common stocks
          common_stocks = top_n_high.intersection(top_n_low)

          # Filter the sector_df for common stocks
          common_stocks_df = sector_df[sector_df['Stock'].isin(common_stocks)].copy()
          common_stocks_df['Sector'] = sector  # Add sector column

          # Append to the list
          all_common_stocks.append(common_stocks_df)


  # Combine all sector common stocks into one DataFrame
  final_common_stocks_df = pd.concat(all_common_stocks, ignore_index=True)


  final_common_stocks_df_high = final_common_stocks_df[["Stock", "Mean_High", "Sector"]].sort_values(by='Mean_High', ascending=False)
  final_common_stocks_df_low = final_common_stocks_df[["Stock", "Mean_Low", "Sector"]].sort_values(by='Mean_Low')


  # Find common stocks between high and low DataFrames
  common_stocks_final = set(final_common_stocks_df_high['Stock']).intersection(final_common_stocks_df_low['Stock'])

  # Filter the original DataFrame for these common stocks
  final_common_stocks = final_common_stocks_df[final_common_stocks_df['Stock'].isin(common_stocks_final)]

  # Calculate the number of common stocks
  num_common_stocks = len(final_common_stocks)

  # If the count exceeds 30, limit it to 30 stocks
  if num_common_stocks > 30:
      final_common_stocks = final_common_stocks.head(30)

  return final_common_stocks

  # Final output
  # print(f"Number of common stocks: {min(num_common_stocks, 30)}")
  # print(final_common_stocks)

"""**Backtesting for the portfolio stocks**

"""

def Backtesting(final_common_stocks, start_date, end_date):
  stocks = final_common_stocks['Stock'].to_list()
  temp = []
  for symbol in stocks:
    temp.append(symbol+".NS")
  stocks = temp

  # start_date '2024-04-01'
  # end_date = '2024-10-01'
  index_symbol = '^CNX100'

  stock_data = yf.download(stocks, start=start_date, end=end_date)
  stock_adj_close = stock_data['Close']

  # Download index data
  index_data = yf.download(index_symbol, start=start_date, end=end_date)
  index_adj_close = index_data['Close']

  # Instead of using specific dates, get the first and last dates from the index
  selected_dates = [stock_adj_close.index[0], stock_adj_close.index[-1]]
  stock_prices = stock_adj_close.loc[selected_dates]
  index_prices = index_adj_close.loc[selected_dates]

  #Calculating return for stocks and index
  stock_prices = stock_prices.T
  index_prices = index_prices.T
  stock_prices['returns'] = (stock_prices['2024-09-30'] - stock_prices['2024-04-01'])/stock_prices['2024-04-01']*100
  index_return = (index_prices['2024-09-30']-index_prices['2024-04-01'])/index_prices['2024-04-01']*100
  index_return_value = index_return.iloc[0]

  # Filter stocks whose return is 5% greater than the index return
  selected_stocks = stock_prices[stock_prices['returns'] > index_return_value + 5*0.5]

  # Print filtered stocks
  print("\nStocks with annualized return greater than 5% index return:")
  # print(selected_stocks)

  final_list = selected_stocks.index.to_list()
  final_list_df = pd.DataFrame(final_list, columns=['Stocks'])
  return final_list
  # print(final_list_df)

"""**Code for Monte carlo simulation for weight allocation**"""

def Monte_Carlo(final_list, start_date, end_date):
  stock_symbols = final_list

  # Define the time frame for historical data
  # start_date = '2014-04-01'
  # end_date = '2024-03-31'

  stock_data = yf.download(stock_symbols, start=start_date, end=end_date)['Close']

  # Calculate daily returns
  returns = stock_data.pct_change()
  mean_returns = returns.mean()
  cov_matrix = returns.cov()

  # Check if cov_matrix is empty and handle the case
  if cov_matrix.empty:
      print("Covariance matrix is empty. Check your stock data.")
  else:
      cov_matrix.dropna(inplace=True)  # This line should be executed only if cov_matrix is not empty.
      print(cov_matrix)

  num_assets = len(stock_symbols)
  num_portfolios = 10000

  # Set a random seed for reproducibility
  np.random.seed(42)

  results = []

  for _ in range(num_portfolios):
      weights = np.random.random(num_assets)
      weights /= np.sum(weights)
      portfolio_return = np.sum(mean_returns * weights) * 252  # Annualized return
      portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)  # Annualized volatility
      sharpe_ratio = (portfolio_return - 0.0647)/portfolio_std_dev
      results.append([weights, portfolio_return, portfolio_std_dev, sharpe_ratio])

  # Convert the results to a DataFrame
  results_df = pd.DataFrame(results, columns=['Portfolio_Weights', 'Portfolio_Return', 'Portfolio_StdDev', 'Sharpe_Ratio'])

  max_sharpe_ratio_portfolio = results_df.loc[results_df['Sharpe_Ratio'].idxmax()]

  # Find the portfolio with the minimum standard deviation (risk)
  min_risk_portfolio = results_df.loc[results_df['Portfolio_StdDev'].idxmin()]

  print("Maximum Sharpe Ratio Portfolio:")
  print(max_sharpe_ratio_portfolio)
  print("\nMinimum Risk Portfolio:")
  print(min_risk_portfolio)

  print(max_sharpe_ratio_portfolio['Portfolio_Weights'])
  print(min_risk_portfolio['Portfolio_Weights'])


  plt.figure(figsize=(10, 6))
  plt.scatter(results_df['Portfolio_StdDev'], results_df['Portfolio_Return'], c=results_df['Sharpe_Ratio'], cmap='viridis')
  plt.title('Efficient Frontier')
  plt.xlabel('Portfolio Risk (Standard Deviation)')
  plt.ylabel('Portfolio Return')
  plt.colorbar(label='Sharpe Ratio')
  plt.scatter(max_sharpe_ratio_portfolio['Portfolio_StdDev'], max_sharpe_ratio_portfolio['Portfolio_Return'], c='red', marker='*', s=100, label='Max Sharpe Ratio')
  plt.scatter(min_risk_portfolio['Portfolio_StdDev'], min_risk_portfolio['Portfolio_Return'], c='green', marker='*', s=100, label='Min Risk')
  plt.legend()

  plt.show()

  return max_sharpe_ratio_portfolio['Portfolio_Weights']

"""**Code for creating dataset with technical indicators**"""

def dataset_creation(final_list, start_date, end_date, output_path):
  # Define your NSE tickers and dates
  nse_tickers = final_list
  # start_date = "2016-02-28"
  # end_date = "2024-03-01"

  # Define the intervals
  intervals = {
      "Daily": "1d",
      "Weekly": "1wk",
      "Monthly": "1mo"
  }

  # Set output directory path to Google Drive
  output_dir = output_path   #'/content/drive/MyDrive/nse_data'
  os.makedirs(output_dir, exist_ok=True)

  # Download data for each ticker and each interval
  for ticker in nse_tickers:
      for interval_name, interval in intervals.items():
          try:
              # Download historical data with specific interval
              data = yf.download(ticker, start=start_date, end=end_date, interval=interval)

              # Reorder columns and reset index to make Date a column
              if not data.empty:
                  data.reset_index(inplace=True)  # Convert Date index into a column
                  data = data[['Date', 'Close', 'High', 'Low', 'Open', 'Volume']]  # Ensure correct order

                  # Save to CSV with Date as a column
                  sub_dir = os.path.join(output_dir, interval_name)
                  os.makedirs(sub_dir, exist_ok=True)
                  csv_file = os.path.join(sub_dir, f"{ticker.replace('.NS', '')}_{interval_name}.csv")
                  data.to_csv(csv_file, index=False, header=True)  # Do not save index

                  print(f"Saved {interval_name} data for {ticker} to {csv_file}")
              else:
                  print(f"No {interval_name} data found for {ticker}")
          except Exception as e:
              print(f"Error downloading {interval_name} data for {ticker}: {e}")

def indicators_dataset(folder_path):
  def read_csv(file_path):
      df = pd.read_csv(file_path)
      df['Date'] = pd.to_datetime(df['Date'])
      return df

  def calculate_monthly_indicators(df):
      df['SMA_20'] = ta.sma(df['Close'], timeperiod=20)
      df['Choppiness_Index'] = ta.adx(df['High'], df['Low'], df['Close'], timeperiod=14)['ADX_14']
      ST = ta.atr(df["High"], df["Low"], df["Close"], timeperiod=14)  # Example for SuperTrend (adjust as needed)
      df["SuperTrend"] = ST
      return df[['Date', 'Open', 'Close', 'High','Volume', 'SMA_20', 'Choppiness_Index', 'SuperTrend']]

  def calculate_weekly_indicators(df):
      macd_result = ta.macd(df["Close"], fastperiod=12, slowperiod=26, signalperiod=9)
      df["MACD"] = macd_result["MACD_12_26_9"]
      df["MACD_Signal"] = macd_result["MACDs_12_26_9"]
      df['RSI'] = ta.rsi(df['Close'], timeperiod=14)
      df['SMA_50'] = ta.sma(df['Close'], timeperiod=50)
      df['EMA_20'] = ta.ema(df['Close'], timeperiod=20)
      df['EMA_10'] = ta.ema(df['Close'], timeperiod=10)
      return df[['Date','Open', 'Close','High', 'MACD', 'MACD_Signal', 'RSI', 'SMA_50', 'EMA_20', 'EMA_10']]

  def calculate_daily_indicators(df):
      df['VWSMA_200'] = df['Close'].rolling(window=200).mean()
      df['VWEMA_50'] = df['Close'].ewm(span=50, adjust=False).mean()
      df['VWEMA_20'] = df['Close'].ewm(span=20, adjust=False).mean()
      df['RSI_Daily'] = ta.rsi(df['Close'], timeperiod=14)
      adx_indicators = ta.adx(df['High'], df['Low'], df['Close'], timeperiod=14)
      df['ADX'] = adx_indicators['ADX_14']
      return df[['Date','Open', 'Close', 'High', 'Low','VWSMA_200', 'VWEMA_50', 'VWEMA_20', 'RSI_Daily', 'ADX']]

  def main():
      # Specify the base directory containing stock data
      stock_data_folder = folder_path #"/content/drive/MyDrive/nse_data"  # Replace with actual path
      subfolders = ["Daily", "Weekly", "Monthly"]

      for subfolder in subfolders:
          subfolder_path = os.path.join(stock_data_folder, subfolder)
          for file in os.listdir(subfolder_path):
              if file.endswith('.csv'):
                  file_path = os.path.join(subfolder_path, file)
                  df = pd.read_csv(file_path, skiprows = [1])
                  df['Date'] = pd.to_datetime(df['Date'])

                  interval_name = file.split('_')[1].split('.')[0]
                  stock_name = file.split('_')[0]

                  # Apply relevant indicator calculations
                  if interval_name == 'Daily':
                      indicators_df = calculate_daily_indicators(df)
                      indicators_df = indicators_df.dropna()
                  elif interval_name == 'Weekly':
                      indicators_df = calculate_weekly_indicators(df)
                      indicators_df = indicators_df.dropna()
                  else:  # Monthly
                      indicators_df = calculate_monthly_indicators(df)
                      indicators_df = indicators_df.dropna()


                  output_file_path = os.path.join(subfolder_path, f"{stock_name}_{interval_name}.csv")
                  indicators_df.to_csv(output_file_path, index=False)
                  print(f"Saved indicators to {output_file_path}")

  main()

"""**Strategy for trading on stocks selected**"""

def calculate_buy_sell_tags(daily_data):
    buy_results = []
    sell_results = []

    daily_data['ATR'] = ta.atr(daily_data['High'], daily_data['Low'], daily_data['Close'], timeperiod=14)

    for index, row in daily_data.iterrows():
        date = pd.to_datetime(row['Date'])


        # Indicators
        current_price = (row['Open'] + row['Close']) / 2
        sma_200 = row['VWSMA_200']  # 200-day SMA
        ema_50 = row['VWEMA_50']  # 50-day EMA
        ema_20 = row['VWEMA_20']
        rsi = row['RSI_Daily']

        # Buy Logic: Trend + Volatility Breakout + RSI
        if (current_price > sma_200 and
            current_price > ema_50 and
            current_price > ema_20 and
            rsi < 70):  # Ensure RSI is not overbought  and #
            buy_results.append((row['Date'], 1))
        else:
            buy_results.append((row['Date'], 0))

        # Sell Logic: Trend Reversal + RSI + ATR Stop
        if (current_price < ema_50 or
            rsi > 70):  # ATR-based trailing stop
            sell_results.append((row['Date'], 1))
        else:
            sell_results.append((row['Date'], 0))

    return buy_results, sell_results


# Function to generate transactions and calculate returns
def generate_transactions(daily_data, result_df, script):
    transactions = []
    holding = False  # Track whether we currently hold a position
    buy_date = None
    buy_price = None

    for index, row in result_df.iterrows():
        if row['Buy_Tag'] == 1 and not holding:
            # Record the buy date and price
            buy_date = row['Date']
            buy_row = daily_data[daily_data['Date'] == buy_date].iloc[0]
            buy_price = (buy_row['Open'] + buy_row['Close']) / 2
            holding = True  # We are now holding a position

        elif row['Sell_Tag'] == 1 and holding:
            # Record the sell date and price
            sell_date = row['Date']
            sell_row = daily_data[daily_data['Date'] == sell_date].iloc[0]
            sell_price = (sell_row['Open'] + sell_row['Close']) / 2

            # Calculate transaction return and store it
            transaction_return = sell_price - buy_price
            transactions.append((script, buy_date, sell_date, transaction_return))

            # Reset holding flag
            holding = False

    # Return the transactions as a DataFrame
    return pd.DataFrame(transactions, columns=['Script', 'Buy_Date', 'Sell_Date', 'Return'])

"""**Code for Continuous looping**"""

def closed_loop(Init_amt, Weights, stock_list, folder_path, result_dfs):
    scripts = [stock.split('.')[0] for stock in stock_list]  # Remove ".NS"
    money_alloted = {scripts[i]: Init_amt * Weights[i] for i in range(len(scripts))}
    total_portfolio_value = Init_amt  # Track total portfolio value

    transactions = []  # Store transactions for tracking

    for script in scripts:
        # Load stock's daily data
        daily_data = pd.read_csv(f'{folder_path}/Daily/{script}_Daily.csv')

        # Use precomputed result_df instead of reading from CSV
        result_df = result_dfs[script]

        holding = False
        buy_price = None
        shares_bought = 0

        for index, row in result_df.iterrows():
            if row['Buy_Tag'] == 1 and not holding:
                buy_date = row['Date']
                buy_row = daily_data[daily_data['Date'] == buy_date]

                if not buy_row.empty:
                    buy_price = (buy_row.iloc[0]['Open'] + buy_row.iloc[0]['Close']) / 2
                    shares_bought = money_alloted[script] / buy_price  # Calculate shares
                    holding = True  # Mark as holding position

            elif row['Sell_Tag'] == 1 and holding:
                sell_date = row['Date']
                sell_row = daily_data[daily_data['Date'] == sell_date]

                if not sell_row.empty:
                    sell_price = (sell_row.iloc[0]['Open'] + sell_row.iloc[0]['Close']) / 2
                    trade_profit = shares_bought * (sell_price - buy_price)

                    # Update money allotted to this stock
                    money_alloted[script] += trade_profit

                    # Update total portfolio value
                    total_portfolio_value += trade_profit

                    transactions.append({
                        'Stock': script,
                        'Buy_Date': buy_date,
                        'Sell_Date': sell_date,
                        'Buy_Price': buy_price,
                        'Sell_Price': sell_price,
                        'Shares': shares_bought,
                        'Profit/Loss': trade_profit
                    })

                    holding = False  # Reset holding state

    # Final ROI Calculation
    portfolio_return_percentage = ((total_portfolio_value - Init_amt) / Init_amt) * 100

    # Print Summary
    print(f"Final Portfolio Value: {total_portfolio_value}")
    print(f"Total Profit/Loss: {total_portfolio_value - Init_amt}")
    print(f"Portfolio Return Percentage: {portfolio_return_percentage:.2f}%")

    return pd.DataFrame(transactions)

"""**Main function**"""

if __name__ == "__main__":
    # Step 1: Select Stocks Based on Fundamental Analysis
    folder_path_1 = '/content/drive/MyDrive/Project_2_dataset'
    final_common_stocks = stock_selection(folder_path_1)

    # Step 2: Backtesting to Filter Stocks
    back_test_start_date = '2024-04-01'
    back_test_end_date = '2024-10-01'
    final_list = Backtesting(final_common_stocks, back_test_start_date, back_test_end_date)

    # Step 3: Monte Carlo Simulation for Optimal Weights
    monte_carlo_start_date = '2014-04-02'
    monte_carlo_end_date = '2024-03-31'
    optimized_weights = Monte_Carlo(final_list, monte_carlo_start_date, monte_carlo_end_date)

    # Step 4: Creating Dataset with Technical Indicators
    dataset_start_date = "2016-02-28"
    dataset_end_date = "2024-03-01"
    output_path = '/content/drive/MyDrive/nse_data'
    dataset_creation(final_list, dataset_start_date, dataset_end_date, output_path)

    # Step 5: Calculate Technical Indicators
    folder_path_2 = '/content/drive/MyDrive/nse_data'
    indicators_dataset(folder_path_2)

    # Step 6: Generate Buy/Sell Signals and Transactions
    scripts = [stock.split('.')[0] for stock in final_list]  # Remove ".NS"
    result_dfs = {}  # Dictionary to store result_df for each stock

    for script in scripts:
        daily_data = pd.read_csv(f'/content/drive/MyDrive/nse_data/Daily/{script}_Daily.csv')

        # Generate Buy/Sell signals
        buy, sell = calculate_buy_sell_tags(daily_data)
        buy_df = pd.DataFrame(buy, columns=['Date', 'Buy_Tag'])
        sell_df = pd.DataFrame(sell, columns=['Date', 'Sell_Tag'])
        result_df = pd.merge(buy_df, sell_df, on='Date')

        # Store result_df for use in closed_loop()
        result_dfs[script] = result_df

        # Generate transactions for review
        transaction = generate_transactions(daily_data, result_df, script)

    # Step 7: Run Closed Loop Strategy
    Init_amt = 1000000  # Example: Initial capital of 1,000,000
    transactions_df = closed_loop(Init_amt, optimized_weights, final_list, folder_path_2, result_dfs)

    # Step 8: Save the Final Transactions to CSV for Review
    print(transactions_df)
    print("\nClosed-loop strategy execution completed. Results saved to CSV.")